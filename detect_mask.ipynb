{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import models,layers\n",
    "import cv2\n",
    "import pickle\n",
    "import os \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img,ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input,AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Dir = \"/Users/HP/Desktop/Coding/AIML/Face_Mask_Detection/Face_Mask_Dataset/Train\"\n",
    "Val_Dir = \"/Users/HP/Desktop/Coding/AIML/Face_Mask_Detection/Face_Mask_Dataset/Validation\"\n",
    "categories = ['WithMask','WithoutMask']\n",
    "\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "val_data = []\n",
    "val_labels =[]\n",
    "\n",
    "for i in categories:\n",
    "  path = os.path.join(Dir,i)\n",
    "  for j in os.listdir(path):\n",
    "    img_path = os.path.join(path,j)\n",
    "    img = load_img(img_path,target_size=(224,224))\n",
    "    img_arr = img_to_array(img)\n",
    "    img_arr = preprocess_input(img_arr)\n",
    "\n",
    "    data.append(img_arr)\n",
    "    labels.append(i)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data,dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "data_aug = ImageDataGenerator(\n",
    "    rotation_range= 22,\n",
    "    zoom_range = 0.16,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range =0.2,\n",
    "    shear_range=0.20,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False,input_tensor=Input(shape = (224,224,3)))\n",
    "\n",
    "head = base_model.output\n",
    "head = AveragePooling2D(pool_size=(7,7))(head)\n",
    "\n",
    "head = keras.layers.Flatten(name=\"flatten\")(head)\n",
    "head = keras.layers.Dense(128,activation=\"relu\")(head)\n",
    "head = keras.layers.Dropout(0.5)(head)\n",
    "head = keras.layers.Dense(2,activation = \"softmax\")(head)\n",
    "\n",
    "model = keras.models.Model(inputs = base_model.input,outputs = head )\n",
    "\n",
    "for i in base_model.layers:\n",
    "  i.trainable =False\n",
    "\n",
    "output = Adam(learning_rate = INIT_LR,decay =INIT_LR/EPOCHS)\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer = output,metrics=['accuracy'])\n",
    "\n",
    "(train_x, test_x, train_y, test_y) = train_test_split(data, labels,\n",
    "    test_size=0.20, stratify=labels, random_state=38)\n",
    "\n",
    "steps_per_epoch = len(train_x) // BS\n",
    "validation_steps = len(test_x) // BS\n",
    "\n",
    "history = model.fit(\n",
    "    data_aug.flow(train_x, train_y ,batch_size=BS),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=(test_x, test_y),\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31abe152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224), (104.0, 177.0, 123.0))\n",
    "\n",
    "    faceNet.setInput(blob)\n",
    "    detections = faceNet.forward()\n",
    "\n",
    "    faces = []\n",
    "    locs = []\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            (startX, startY) = (max(0, startX), max(0, startY))\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "            face_detect = frame[startY:endY, startX:endX]\n",
    "            face_detect = cv2.cvtColor(face_detect, cv2.COLOR_BGR2RGB)\n",
    "            face_detect = cv2.resize(face_detect, (224, 224))\n",
    "            face_detect = img_to_array(face_detect)\n",
    "            face_detect = preprocess_input(face_detect)\n",
    "\n",
    "            faces.append(face_detect)\n",
    "            locs.append((startX, startY, endX, endY))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        faces = np.array(faces, dtype=\"float32\")\n",
    "        predictions = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "    return (locs, predictions)\n",
    "\n",
    "prototxtPath = r\"Face_detector\\deploy.prototxt\"\n",
    "weightsPath = r\"Face_detector\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "maskNet = load_model(\"mask_detector_new.model\")\n",
    "\n",
    "vs = VideoStream(src=0).start()\n",
    "\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    (locs, predictions) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "\n",
    "    for (box, pred) in zip(locs, predictions):\n",
    "        (startX, startY, endX, endY) = box\n",
    "        (mask, withoutMask) = pred\n",
    "\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "        cv2.putText(frame, label, (startX, startY - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f74c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
